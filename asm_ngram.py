import pandas as pd
from keras.models import Sequential
from keras.layers.core import Dense, Dropout
from keras.optimizers import Adam, SGD

train_data = pd.read_csv("./train_ngram_data.csv")
valid_data = pd.read_csv("./valid_ngram_data.csv")
test_data = pd.read_csv("./test_ngram_data.csv")

train_data = train_data.fillna(0)
valid_data = valid_data.fillna(0)
test_data = test_data.fillna(0)

print(train_data)

### 이름을 제외한 모든 컬럼
noname_train_data = train_data.drop(["name"], axis=1)
noname_valid_data = valid_data.drop(["name"], axis=1)
noname_test_data = test_data.drop(["name"], axis=1)

### assembly 가시성을 위한 하드코딩 진행
ngram50_labels = ['sub and', 'pop mov', 'push lea', 'shl or', 'push sub', 'pop pop',
       'retn call', 'pop retn', 'sub jnz', 'retn cmp', 'shl add', 'push xor',
       'test push', 'retn xor', 'push mov', 'sub xor', 'push push', 'test jg',
       'sub jz', 'sub sar', 'xor and', 'sub test', 'shl mov', 'xor inc',
       'retn mov', 'xor sub', 'shr mov', 'retn push', 'sub add', 'sub jmp',
       'xor call', 'sub sub', 'test jle', 'sub cmp', 'xor add', 'sub lea',
       'sub push', 'test mov', 'xor retn', 'xor lea', 'xor test', 'sub mov',
       'xor jmp', 'test jnz', 'xor xor', 'xor cmp', 'test jz', 'xor pop',
       'xor push', 'xor mov']
# print(noname_train_data.sum().sort_values().tail(50).keys())


column50_train_data = noname_train_data[["mal"] + ngram50_labels]
column50_valid_data = noname_valid_data[["mal"] + ngram50_labels]
column50_test_data = noname_test_data[["mal"] + ngram50_labels]

X_train = column50_train_data.drop('mal', axis=1).values
target_label = column50_train_data['mal'].values

X_val = column50_valid_data.drop('mal', axis=1).values

X_test = column50_test_data.values

print(X_train.shape)
print(X_test.shape)
print(X_val.shape)

nn_model = Sequential()
nn_model.add(Dense(32,activation='relu',input_shape=(14,)))
nn_model.add(Dropout(0.2))
nn_model.add(Dense(64,activation='relu'))
nn_model.add(Dropout(0.2))
nn_model.add(Dense(32,activation='relu'))
nn_model.add(Dropout(0.2))
nn_model.add(Dense(1,activation='sigmoid'))

Loss = 'binary_crossentropy'
nn_model.compile(loss=Loss,optimizer=Adam(),metrics=['accuracy'])
nn_model.summary()

history = nn_model.fit(X_train, batch_size=64, epochs=500, validation_data=X_val, verbose=1)